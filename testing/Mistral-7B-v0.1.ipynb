{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "\n",
    "def test():\n",
    "    \n",
    "    def extract_json_from_text(text):\n",
    "        \"\"\"Extract JSON string from model output using regex\"\"\"\n",
    "        # Try to find JSON within code blocks first\n",
    "        json_match = re.search(r'```(?:json)?\\s*(\\{.*\\})\\s*```', text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json_match.group(1)\n",
    "        \n",
    "        # If no code blocks, try to find the first JSON object\n",
    "        json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json_match.group(0)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # Initialize the model and tokenizer\n",
    "    model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    # Add padding token if it doesn't exist\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    #   # Example invoice text\n",
    "    invoice_text = \"\"\"\n",
    "      Invoice No: INV-12345\n",
    "      Date: 2023-10-05\n",
    "      Due Date: 2023-11-05\n",
    "      Bill To: John Doe, 123 Main St, Cityville\n",
    "      Item: Consulting Services, Quantity: 5, Rate: $100.00, Total: $500.00\n",
    "      Tax: $50.00, Grand Total: $550.00\n",
    "      \"\"\"\n",
    "   \n",
    "    \n",
    "\n",
    "    # Create a more specific prompt\n",
    "    prompt = f\"\"\"\n",
    "    Convert the following invoice text into a valid JSON object with exactly these keys: \n",
    "    invoice_number, date, due_date, bill_to, items, tax, total.\n",
    "    Items should be a list of dictionaries with keys: description, quantity, unit_price, amount.\n",
    "\n",
    "    Return ONLY the JSON object without any additional text or explanation.\n",
    "\n",
    "    Invoice Text:\n",
    "    {invoice_text}\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=500,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "\n",
    "    # Decode the output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract just the new generated part (remove the prompt)\n",
    "    response = generated_text[len(prompt):].strip()\n",
    "\n",
    "    # Try to extract JSON from the response\n",
    "    json_str = extract_json_from_text(response)\n",
    "\n",
    "    if json_str:\n",
    "        try:\n",
    "            # Parse the JSON\n",
    "            invoice_data = json.loads(json_str)\n",
    "            print(\"Successfully extracted JSON:\")\n",
    "            print(json.dumps(invoice_data, indent=2))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse JSON: {e}\")\n",
    "            print(\"Model output was:\")\n",
    "            print(response)\n",
    "    else:\n",
    "        print(\"No JSON found in response:\")\n",
    "        print(response)\n",
    "\n",
    "    \n",
    "    # Define the output file name for the text file\n",
    "    output_file = \"receipt_output.txt\"\n",
    "\n",
    "        # Open a new file in write mode\n",
    "    with open(output_file, \"w\") as f:\n",
    "            # Write the raw output text to the file\n",
    "            # The [0] is because tokenizer.batch_decode returns a list\n",
    "            # of one string, so we want to get the first and only element.\n",
    "        f.write(json_str)\n",
    "        \n",
    "    print(f\"Successfully saved output to {output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   testing = test()\n",
    "   print(testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eb2266",
   "metadata": {},
   "source": [
    "output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cfc86c",
   "metadata": {},
   "source": [
    "```\n",
    "  {\n",
    "  \"invoice_number\": \"INV-12345\",\n",
    "  \"date\": \"2023-10-05\",\n",
    "  \"due_date\": \"2023-11-05\",\n",
    "  \"bill_to\": {\n",
    "    \"name\": \"John Doe\",\n",
    "    \"address\": \"123 Main St, Cityville\"\n",
    "  },\n",
    "  \"items\": [\n",
    "    {\n",
    "      \"description\": \"Consulting Services\",\n",
    "      \"quantity\": 5,\n",
    "      \"unit_price\": 100.0,\n",
    "      \"amount\": 500.0\n",
    "    }\n",
    "  ],\n",
    "  \"tax\": 50.0,\n",
    "  \"total\": 550.0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import urllib.request \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "from ast import  literal_eval\n",
    "\n",
    "\n",
    "def test():\n",
    "  \n",
    "\n",
    "    \n",
    "    def extract_json_from_text(text):\n",
    "        \"\"\"Extract JSON string from model output using regex\"\"\"\n",
    "        # Try to find JSON within code blocks first\n",
    "        json_match = re.search(r'```(?:json)?\\s*(\\{.*\\})\\s*```', text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json_match.group(1)\n",
    "        \n",
    "        # If no code blocks, try to find the first JSON object\n",
    "        json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json_match.group(0)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # Initialize the model and tokenizer\n",
    "    model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    # Add padding token if it doesn't exist\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    \n",
    "\n",
    "    # pull a random receipt image from internet\n",
    "    image_url='https://groups.google.com/group/jzebra-users/attach/d16dbba8a612edfa/Bill%20Image_Receipt.png?part=0.1'\n",
    "    local_image_id='bill_image_receipt.png'\n",
    "    urllib.request.urlretrieve(image_url,local_image_id) \n",
    "    receipt_image = Image.open(local_image_id)\n",
    "    receipt_image_array = np.array(receipt_image.convert('RGB'))\n",
    "\n",
    "    ocr = PaddleOCR(lang=\"en\",\n",
    "                ocr_version=\"PP-OCRv4\")\n",
    "\n",
    "    def paddle_scan(paddleocr, \n",
    "                    img_path_or_nparray):\n",
    "\n",
    "        result = ocr.predict(img_path_or_nparray)\n",
    "        result = result[0]\n",
    "        txts = result['rec_texts']\n",
    "        \n",
    "        return txts, result\n",
    "\n",
    "\n",
    "    # perform ocr scan\n",
    "    receipt_texts, receipt_boxes = paddle_scan(ocr,receipt_image_array)\n",
    "    \n",
    "        \n",
    "\n",
    "    # --------------------\n",
    "\n",
    "    # Create a more specific prompt\n",
    "    prompt = f\"\"\"\n",
    "    Convert the following invoice text into a valid JSON object with exactly these keys: \n",
    "    invoice_number, date, due_date, bill_to, items, tax, total.\n",
    "    Items should be a list of dictionaries with keys: description, quantity, unit_price, amount.\n",
    "\n",
    "    Return ONLY the JSON object without any additional text or explanation.\n",
    "\n",
    "    Invoice Text:\n",
    "    {receipt_texts}\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=500,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "\n",
    "    # Decode the output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract just the new generated part (remove the prompt)\n",
    "    response = generated_text[len(prompt):].strip()\n",
    "\n",
    "    # Try to extract JSON from the response\n",
    "    json_str = extract_json_from_text(response)\n",
    "\n",
    "    if json_str:\n",
    "        try:\n",
    "            # Parse the JSON\n",
    "            invoice_data = json.loads(json_str)\n",
    "            print(\"Successfully extracted JSON:\")\n",
    "            print(json.dumps(invoice_data, indent=2))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse JSON: {e}\")\n",
    "            print(\"Model output was:\")\n",
    "            print(response)\n",
    "    else:\n",
    "        print(\"No JSON found in response:\")\n",
    "        print(response)\n",
    "\n",
    "\n",
    "    \n",
    "    # Define the output file name for the text file\n",
    "    output_file = \"receipt_output.txt\"\n",
    "\n",
    "        # Open a new file in write mode\n",
    "    with open(output_file, \"w\") as f:\n",
    "            # Write the raw output text to the file\n",
    "            # The [0] is because tokenizer.batch_decode returns a list\n",
    "            # of one string, so we want to get the first and only element.\n",
    "        f.write(generated_text)\n",
    "        \n",
    "    print(f\"Successfully saved output to {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   testing = test()\n",
    "   print(testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68697d",
   "metadata": {},
   "source": [
    "output: \n",
    "```\n",
    "    Successfully extracted JSON:\n",
    "{\n",
    "\n",
    "    {  \"description\": \"Heineken Draft Standard\",\n",
    "      \"quantity\": \"3\",\n",
    "      \"unit_price\": \"24.60\",\n",
    "      \"amount\": \"73.80\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Heineken Draft Half Liter\",\n",
    "      \"quantity\": \"1\",\n",
    "      \"unit_price\": \"15.20\",\n",
    "      \"amount\": \"15.20\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Carlsberg Bucket (5 bottles)\",\n",
    "      \"quantity\": \"2\",\n",
    "      \"unit_price\": \"80.00\",\n",
    "      \"amount\": \"160.00\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Grilled Chicken Breast\",\n",
    "      \"quantity\": \"4\",\n",
    "      \"unit_price\": \"74.00\",\n",
    "      \"amount\": \"296.00\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Sirloin Steak\",\n",
    "      \"quantity\": \"3\",\n",
    "      \"unit_price\": \"96.00\",\n",
    "      \"amount\": \"288.00\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Coke\",\n",
    "      \"quantity\": \"1\",\n",
    "      \"unit_price\": \"3.50\",\n",
    "      \"amount\": \"3.50\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Ice Cream\",\n",
    "      \"quantity\": \"5\",\n",
    "      \"unit_price\": \"18.00\",\n",
    "      \"amount\": \"90.00\"\n",
    "    }\n",
    "  ],\n",
    "  \"tax\": \"16.36\",\n",
    "  \"total\"}\n",
    "      \"unit_price\": \"24.60\",\n",
    "      \"amount\": \"73.80\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Heineken Draft Half Liter\",\n",
    "      \"quantity\": \"1\",\n",
    "      \"unit_price\": \"15.20\",\n",
    "      \"amount\": \"15.20\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Carlsberg Bucket (5 bottles)\",\n",
    "      \"quantity\": \"2\",\n",
    "      \"unit_price\": \"80.00\",\n",
    "      \"amount\": \"160.00\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Grilled Chicken Breast\",\n",
    "      \"quantity\": \"4\",\n",
    "      \"unit_price\": \"74.00\",\n",
    "      \"amount\": \"296.00\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Sirloin Steak\",\n",
    "      \"quantity\": \"3\",\n",
    "      \"unit_price\": \"96.00\",\n",
    "      \"amount\": \"288.00\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Coke\",\n",
    "      \"quantity\": \"1\",\n",
    "      \"unit_price\": \"3.50\",\n",
    "      \"amount\": \"3.50\"\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"Ice Cream\",\n",
    "      \"quantity\": \"5\",\n",
    "      \"unit_price\": \"18.00\",\n",
    "      \"amount\": \"90.00\"\n",
    "    }\n",
    "  ],\n",
    "  \"tax\": \"16.36\",\n",
    "  \"total\": \"376.40\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354ade2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
